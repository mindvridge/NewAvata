# ============================================================================
# Docker Compose for Realtime Interview Avatar with MuseTalk Real-time
# GPU-enabled container with mmpose support
# ============================================================================

version: '3.8'

services:
  # --------------------------------------------------------------------------
  # Redis - Session management and caching
  # --------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: interview-redis
    restart: unless-stopped
    command: >
      redis-server
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - interview-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # --------------------------------------------------------------------------
  # Interview Avatar Application with Real-time MuseTalk
  # --------------------------------------------------------------------------
  avatar:
    build:
      context: .
      dockerfile: docker/Dockerfile.realtime
    image: interview-avatar-realtime:latest
    container_name: interview-avatar-realtime
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      # Application
      - APP_ENV=production
      - LOG_LEVEL=INFO
      - DEBUG=false

      # Redis
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0

      # GPU
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0

      # API Keys (from .env file)
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}

      # Model paths
      - MODELS_DIR=/app/models
      - AVATAR_SOURCE_IMAGE=/app/assets/images/avatar.jpg

      # Performance
      - AVATAR_FPS=25
      - USE_FLOAT16=true
      - SILENCE_BLEND=true
      - BATCH_SIZE=8

    volumes:
      # Models (mount from host to avoid re-downloading)
      - ../MuseTalk/models:/app/models:ro
      - ./assets:/app/assets:ro

      # Data directories
      - avatar_data:/app/data
      - avatar_logs:/app/logs
      - avatar_results:/app/results

      # Optional: Mount source for development
      # - ./src:/app/src

    networks:
      - interview-network

    # GPU support
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    # Shared memory for PyTorch
    shm_size: '8gb'

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

# ============================================================================
# Networks
# ============================================================================
networks:
  interview-network:
    driver: bridge

# ============================================================================
# Volumes
# ============================================================================
volumes:
  redis_data:
    driver: local
  avatar_data:
    driver: local
  avatar_logs:
    driver: local
  avatar_results:
    driver: local

# ============================================================================
# Usage
# ============================================================================
#
# 1. Create .env file with API keys:
#    DEEPGRAM_API_KEY=your_key
#    ELEVENLABS_API_KEY=your_key
#    OPENAI_API_KEY=your_key
#
# 2. Build and start:
#    docker-compose -f docker-compose.realtime.yml up --build
#
# 3. Background mode:
#    docker-compose -f docker-compose.realtime.yml up -d
#
# 4. View logs:
#    docker-compose -f docker-compose.realtime.yml logs -f avatar
#
# 5. Stop:
#    docker-compose -f docker-compose.realtime.yml down
#
# 6. Stop and remove volumes:
#    docker-compose -f docker-compose.realtime.yml down -v
#
# ============================================================================
