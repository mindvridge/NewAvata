# ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ê°€ì´ë“œ

ì‹¤ì‹œê°„ ë©´ì ‘ ì•„ë°”íƒ€ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

## ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
- [ì¸¡ì • ë©”íŠ¸ë¦­](#ì¸¡ì •-ë©”íŠ¸ë¦­)
- [ì„±ëŠ¥ ëª©í‘œ](#ì„±ëŠ¥-ëª©í‘œ)
- [í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ í•´ì„](#í”„ë¡œíŒŒì¼ë§-ê²°ê³¼-í•´ì„)
- [ìµœì í™” ê°€ì´ë“œ](#ìµœì í™”-ê°€ì´ë“œ)
- [ê³ ê¸‰ ì‚¬ìš©ë²•](#ê³ ê¸‰-ì‚¬ìš©ë²•)

---

## ê°œìš”

`scripts/profile.py`ëŠ” ê° ì»´í¬ë„ŒíŠ¸(STT, LLM, TTS, Avatar)ì˜ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ë³‘ëª© êµ¬ê°„ì„ ì‹ë³„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

- â±ï¸ **ë ˆì´í„´ì‹œ ë²¤ì¹˜ë§ˆí¬**: P50/P95/P99 ë ˆì´í„´ì‹œ ì¸¡ì •
- ğŸ’¾ **ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§**: RSS/VMS ì¶”ì , ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íƒì§€
- ğŸ® **GPU ëª¨ë‹ˆí„°ë§**: VRAM ì‚¬ìš©ëŸ‰, í™œìš©ë¥ , ì˜¨ë„
- ğŸ“Š **ì‹œê°í™”**: matplotlib ê¸°ë°˜ ì°¨íŠ¸ ìë™ ìƒì„±
- ğŸ“ **JSON ë¦¬í¬íŠ¸**: êµ¬ì¡°í™”ëœ ì„±ëŠ¥ ë°ì´í„° ì €ì¥

---

## ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install numpy psutil matplotlib

# GPU ëª¨ë‹ˆí„°ë§ (ì„ íƒ)
pip install nvidia-ml-py3
```

### 2. ì „ì²´ í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰

```bash
python scripts/profile.py
```

ì‹¤í–‰ ê²°ê³¼:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            ğŸ” ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‹œì‘                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š STT í”„ë¡œíŒŒì¼ë§ ì¤‘...
  ì§„í–‰: 5/20 (í‰ê· : 145.23ms)
  ì§„í–‰: 10/20 (í‰ê· : 142.67ms)
  ì§„í–‰: 15/20 (í‰ê· : 140.12ms)
  ì§„í–‰: 20/20 (í‰ê· : 138.45ms)

ğŸ“Š LLM í”„ë¡œíŒŒì¼ë§ ì¤‘...
  ì§„í–‰: 2/10 (TTFT í‰ê· : 185.34ms)
  ì§„í–‰: 4/10 (TTFT í‰ê· : 180.12ms)
  ...

============================================================
ğŸ“Š í”„ë¡œíŒŒì¼ë§ ê²°ê³¼
============================================================

ã€STTã€‘
  ë ˆì´í„´ì‹œ:
    â€¢ í‰ê· :  138.45ms
    â€¢ ì¤‘ì•™ê°’: 135.23ms
    â€¢ P95:   165.34ms
    â€¢ P99:   178.12ms
    â€¢ í‘œì¤€í¸ì°¨: 12.34ms
  ë©”ëª¨ë¦¬:
    â€¢ ì‚¬ìš© ì „: 1250.5MB
    â€¢ ì‚¬ìš© í›„: 1275.3MB
    â€¢ ì¦ê°€ëŸ‰:  24.8MB
  ì²˜ë¦¬ëŸ‰: 7.2 ops/s

ã€LLMã€‘
  ...
```

### 3. ê²°ê³¼ í™•ì¸

í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤:

```
profile_results/
â”œâ”€â”€ profile_20250105_120000.json     # JSON ë¦¬í¬íŠ¸
â”œâ”€â”€ latency_20250105_120000.png      # ë ˆì´í„´ì‹œ ì°¨íŠ¸
â”œâ”€â”€ memory_20250105_120000.png       # ë©”ëª¨ë¦¬ ì°¨íŠ¸
â””â”€â”€ gpu_20250105_120000.png          # GPU ì°¨íŠ¸
```

---

## ì¸¡ì • ë©”íŠ¸ë¦­

### 1. ë ˆì´í„´ì‹œ ë©”íŠ¸ë¦­

ê° ì»´í¬ë„ŒíŠ¸ì˜ ì‘ë‹µ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

| ë©”íŠ¸ë¦­ | ì„¤ëª… |
|--------|------|
| **í‰ê·  (Mean)** | ëª¨ë“  ìƒ˜í”Œì˜ í‰ê·  ë ˆì´í„´ì‹œ |
| **ì¤‘ì•™ê°’ (Median)** | 50% ì§€ì  ë ˆì´í„´ì‹œ (P50) |
| **P95** | 95% ì§€ì  ë ˆì´í„´ì‹œ (ìƒìœ„ 5% ì œì™¸) |
| **P99** | 99% ì§€ì  ë ˆì´í„´ì‹œ (ìƒìœ„ 1% ì œì™¸) |
| **í‘œì¤€í¸ì°¨ (Std)** | ë ˆì´í„´ì‹œ ë³€ë™ í­ |

**ì£¼ìš” ì§€í‘œ**:
- **STT**: ì˜¤ë””ì˜¤ ì…ë ¥ë¶€í„° í…ìŠ¤íŠ¸ ì¶œë ¥ê¹Œì§€
- **LLM TTFT**: Time To First Token (ì²« í† í° ìƒì„±ê¹Œì§€)
- **TTS TTFB**: Time To First Byte (ì²« ì˜¤ë””ì˜¤ ì²­í¬ê¹Œì§€)
- **Avatar**: í”„ë ˆì„ë‹¹ ë Œë”ë§ ì‹œê°„

### 2. ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | ì„¤ëª… |
|--------|------|
| **RSS** | Resident Set Size (ë¬¼ë¦¬ ë©”ëª¨ë¦¬) |
| **VMS** | Virtual Memory Size (ê°€ìƒ ë©”ëª¨ë¦¬) |
| **Delta** | ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰ ì „í›„ ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ |

**ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒë‹¨**:
- Delta > 100MB: ì˜ì‹¬
- Delta > 200MB: í™•ì‹¤

### 3. GPU ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | ì„¤ëª… |
|--------|------|
| **VRAM ì‚¬ìš©ëŸ‰** | GPU ë©”ëª¨ë¦¬ ì‚¬ìš© (MB) |
| **VRAM ì‚¬ìš©ë¥ ** | ì „ì²´ VRAM ëŒ€ë¹„ ì‚¬ìš© ë¹„ìœ¨ (%) |
| **GPU í™œìš©ë¥ ** | GPU ì½”ì–´ ì‚¬ìš©ë¥  (%) |
| **ì˜¨ë„** | GPU ì˜¨ë„ (Â°C) |

**ë³‘ëª© íŒë‹¨**:
- VRAM ì‚¬ìš©ë¥  > 90%: ë©”ëª¨ë¦¬ ë¶€ì¡±
- GPU í™œìš©ë¥  < 30%: CPU ë³‘ëª© ê°€ëŠ¥ì„±
- ì˜¨ë„ > 85Â°C: ì“°ë¡œí‹€ë§ ê°€ëŠ¥ì„±

---

## ì„±ëŠ¥ ëª©í‘œ

### ë ˆì´í„´ì‹œ ëª©í‘œ

| ì»´í¬ë„ŒíŠ¸ | ëª©í‘œ (P95) | ì´ìœ  |
|----------|-----------|------|
| **STT** | < 100ms | ì‹¤ì‹œê°„ ëŒ€í™” ìœ„í•´ ë¹ ë¥¸ ì¸ì‹ í•„ìˆ˜ |
| **LLM TTFT** | < 200ms | ì²« ì‘ë‹µê¹Œì§€ ì§€ì—° ìµœì†Œí™” |
| **TTS TTFB** | < 200ms | ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì§€ì—° ìµœì†Œí™” |
| **Avatar** | < 50ms/frame | 25 FPS ìœ ì§€ (40ms + ì—¬ìœ ) |

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª©í‘œ

- **End-to-End ë ˆì´í„´ì‹œ**: < 500ms (TTS ìŠ¤íŠ¸ë¦¬ë° ì œì™¸)
- **ì²˜ë¦¬ëŸ‰**: > 5 requests/sec (ë™ì‹œ ì„¸ì…˜)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: < 4GB (ì„¸ì…˜ë‹¹)
- **GPU ë©”ëª¨ë¦¬**: < 6GB (RTX 4090 ê¸°ì¤€)

---

## í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ í•´ì„

### ì˜ˆì œ ë¦¬í¬íŠ¸

```json
{
  "timestamp": "2025-01-05T12:00:00",
  "duration_sec": 45.67,
  "components": {
    "STT": {
      "latency": {
        "mean": 138.45,
        "p95": 165.34,
        "p99": 178.12
      },
      "memory_delta_mb": 24.8,
      "throughput_per_sec": 7.2
    },
    "LLM": {
      "latency": {
        "mean": 180.67,
        "p95": 220.45,
        "p99": 250.12
      },
      "memory_delta_mb": 50.2,
      "throughput_per_sec": 5.5
    },
    ...
  },
  "bottlenecks": [
    "LLM: P95 220.45ms (ëª©í‘œ 200ms ëŒ€ë¹„ 10.2% ì´ˆê³¼)"
  ],
  "recommendations": [
    "LLM: ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš© (GPT-4o â†’ GPT-4o-mini)",
    "TTS: ê³µí†µ ì§ˆë¬¸ ìºì‹± í™œì„±í™” (TTSCache)"
  ]
}
```

### í•´ì„ ê°€ì´ë“œ

#### âœ… ì •ìƒ (Good)

```
ã€STTã€‘
  ë ˆì´í„´ì‹œ:
    â€¢ P95: 95.23ms    âœ“ ëª©í‘œ 100ms ë‹¬ì„±
  ë©”ëª¨ë¦¬:
    â€¢ ì¦ê°€ëŸ‰: 20.5MB  âœ“ í•©ë¦¬ì 
```

**ì˜ë¯¸**: STTê°€ ëª©í‘œ ë ˆì´í„´ì‹œë¥¼ ë‹¬ì„±í•˜ê³  ë©”ëª¨ë¦¬ë„ ì•ˆì •ì 

#### âš ï¸ ì£¼ì˜ (Warning)

```
ã€LLMã€‘
  ë ˆì´í„´ì‹œ:
    â€¢ P95: 220.45ms   âš  ëª©í‘œ 200ms ì´ˆê³¼
    â€¢ í‘œì¤€í¸ì°¨: 85.3ms  âš  ë†’ì€ ë³€ë™ì„±
```

**ì˜ë¯¸**: LLMì´ ì•½ê°„ ëŠë¦¬ê³  ë ˆì´í„´ì‹œê°€ ë¶ˆì•ˆì •í•¨

#### âŒ ë¬¸ì œ (Critical)

```
ã€Avatarã€‘
  ë ˆì´í„´ì‹œ:
    â€¢ P95: 120.45ms   âŒ ëª©í‘œ 50ms ëŒ€í­ ì´ˆê³¼
  GPU:
    â€¢ VRAM: 95.2%     âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±
```

**ì˜ë¯¸**: Avatar ë Œë”ë§ì´ ë§¤ìš° ëŠë¦¬ê³  GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

---

## ìµœì í™” ê°€ì´ë“œ

### STT ìµœì í™”

#### ë¬¸ì œ: P95 > 100ms

**ì›ì¸**:
- VAD ì„¤ì • ë¶€ì ì ˆ (ì²­í¬ í¬ê¸° ë„ˆë¬´ í¼)
- ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ
- API ì„œë²„ ìœ„ì¹˜

**í•´ê²°ì±…**:

1. **VAD ì„¤ì • ì¡°ì •**
```python
# src/stt/vad_config.py
VAD_PRESETS = {
    "INTERVIEW_FAST": SileroVADConfig(
        threshold=0.4,          # ë” ë¯¼ê°í•˜ê²Œ (0.5 â†’ 0.4)
        min_speech_duration_ms=200,  # ë” ì§§ê²Œ (250 â†’ 200)
        max_speech_duration_ms=5000,  # ë” ì§§ê²Œ (10000 â†’ 5000)
    )
}
```

2. **Deepgram ì§€ì—­ ì„ íƒ**
```python
# .env
DEEPGRAM_REGION=us-west-1  # ê°€ì¥ ê°€ê¹Œìš´ ì§€ì—­
```

3. **ëŒ€ì•ˆ STT ì‚¬ìš©**
- Whisper (ë¡œì»¬): ë„¤íŠ¸ì›Œí¬ ë ˆì´í„´ì‹œ 0ms, but GPU í•„ìš”
- AssemblyAI: Deepgram ëŒ€ì•ˆ

### LLM ìµœì í™”

#### ë¬¸ì œ: TTFT > 200ms

**ì›ì¸**:
- ëª¨ë¸ í¬ê¸° (GPT-4o)
- ê¸´ í”„ë¡¬í”„íŠ¸
- ë†’ì€ temperature

**í•´ê²°ì±…**:

1. **ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©**
```python
# src/llm/interviewer_agent.py
MODEL_CONFIGS = {
    "fast": "gpt-4o-mini",      # TTFT ~100ms
    "balanced": "gpt-4o",        # TTFT ~150ms
    "quality": "gpt-4-turbo",    # TTFT ~250ms
}
```

2. **í”„ë¡¬í”„íŠ¸ ìµœì í™”**
```python
# ê¸´ í”„ë¡¬í”„íŠ¸ â†’ ì§§ì€ í”„ë¡¬í”„íŠ¸
# Before (500 tokens)
prompt = f"You are an AI interviewer... [ê¸´ ì„¤ëª…]"

# After (200 tokens)
prompt = f"AI interviewer. Ask about: {topic}. Be concise."
```

3. **Streaming ìµœì í™”**
```python
# temperature ë‚®ì¶”ê¸° (ë³€ë™ì„± ê°ì†Œ)
temperature=0.7  # â†’ 0.5
```

### TTS ìµœì í™”

#### ë¬¸ì œ: TTFB > 200ms

**ì›ì¸**:
- ElevenLabs API ë ˆì´í„´ì‹œ
- ìºì‹± ë¯¸ì‚¬ìš©
- ê¸´ í…ìŠ¤íŠ¸

**í•´ê²°ì±…**:

1. **ìºì‹± í™œì„±í™”**
```python
# src/tts/cache.py
cache = TTSCache(
    max_size=1000,
    enable_disk_cache=True,
)

# ê³µí†µ ì§ˆë¬¸ prewarming
COMMON_QUESTIONS = [
    "ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤",
    "ê²½ë ¥ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”",
    ...
]
await cache.prewarm(COMMON_QUESTIONS)
```

2. **ì²­í¬ í¬ê¸° ìµœì í™”**
```python
# ê¸´ í…ìŠ¤íŠ¸ â†’ ë¬¸ì¥ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°
async def stream_by_sentence(text: str):
    sentences = text.split('. ')
    for sentence in sentences:
        async for chunk in tts.stream_audio(sentence):
            yield chunk
```

3. **ëŒ€ì•ˆ TTS ì‚¬ìš©**
- EdgeTTS (ë¬´ë£Œ): TTFB ~50ms, but í’ˆì§ˆ ë‚®ìŒ
- Naver Clova: TTFB ~100ms, í•œêµ­ì–´ ìµœì 

### Avatar ìµœì í™”

#### ë¬¸ì œ: í”„ë ˆì„ë‹¹ > 50ms

**ì›ì¸**:
- Face enhancement í™œì„±í™”
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
- ë°°ì¹˜ ì‚¬ì´ì¦ˆ ë„ˆë¬´ í¼

**í•´ê²°ì±…**:

1. **Face enhancement ë¹„í™œì„±í™”**
```python
# src/avatar/musetalk_wrapper.py
config = MuseTalkConfig(
    enable_face_enhancement=False,  # True â†’ False (30ms ì ˆê°)
)
```

2. **GPU ë©”ëª¨ë¦¬ ìµœì í™”**
```python
# ë°°ì¹˜ ì‚¬ì´ì¦ˆ ê°ì†Œ
batch_size=1  # 4 â†’ 1

# Mixed precision
torch.set_default_dtype(torch.float16)
```

3. **GPU ì—…ê·¸ë ˆì´ë“œ**
- RTX 3090 â†’ RTX 4090: 2ë°° ë¹ ë¦„
- RTX 4090 â†’ A100: 1.5ë°° ë¹ ë¦„

### ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í•´ê²°

#### ë¬¸ì œ: Delta > 100MB

**ì›ì¸**:
- ìºì‹œ ë¬´ì œí•œ ì¦ê°€
- GPU í…ì„œ ë¯¸í•´ì œ
- ìˆœí™˜ ì°¸ì¡°

**í•´ê²°ì±…**:

1. **ìºì‹œ í¬ê¸° ì œí•œ**
```python
# LRU ìºì‹œ
from functools import lru_cache

@lru_cache(maxsize=100)
def expensive_function(...):
    ...
```

2. **GPU ë©”ëª¨ë¦¬ ì •ë¦¬**
```python
# ë§¤ Në²ˆì§¸ ìš”ì²­ë§ˆë‹¤
if request_count % 10 == 0:
    torch.cuda.empty_cache()
    gc.collect()
```

3. **ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§**
```bash
# memory_profiler ì‚¬ìš©
pip install memory_profiler
python -m memory_profiler scripts/profile.py
```

---

## ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. íŠ¹ì • ì»´í¬ë„ŒíŠ¸ë§Œ í”„ë¡œíŒŒì¼ë§

```bash
# STTì™€ LLMë§Œ
python scripts/profile.py --components stt llm

# Avatarë§Œ
python scripts/profile.py --components avatar

# TTSë§Œ (ìƒ˜í”Œ 50ê°œ)
python scripts/profile.py --components tts --samples 50
```

### 2. ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì •

```bash
python scripts/profile.py --output-dir results/performance
```

### 3. CI/CD í†µí•©

```yaml
# .github/workflows/performance.yml
name: Performance Benchmark

on:
  schedule:
    - cron: '0 0 * * 0'  # ë§¤ì£¼ ì¼ìš”ì¼

jobs:
  benchmark:
    runs-on: ubuntu-latest-gpu
    steps:
      - uses: actions/checkout@v3

      - name: Run profiler
        run: |
          python scripts/profile.py --output-dir artifacts

      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: performance-report
          path: artifacts/
```

### 4. ì„±ëŠ¥ íšŒê·€ íƒì§€

```python
# scripts/compare_profiles.py
import json

def compare_profiles(baseline_path, current_path):
    with open(baseline_path) as f:
        baseline = json.load(f)
    with open(current_path) as f:
        current = json.load(f)

    for component in baseline['components']:
        baseline_p95 = baseline['components'][component]['latency']['p95']
        current_p95 = current['components'][component]['latency']['p95']

        regression = (current_p95 / baseline_p95 - 1) * 100

        if regression > 10:  # 10% ì´ìƒ ëŠë ¤ì§
            print(f"âš ï¸ {component}: {regression:.1f}% ì„±ëŠ¥ ì €í•˜")

# ì‚¬ìš©
compare_profiles(
    'baseline_20250101.json',
    'profile_results/profile_20250105.json'
)
```

### 5. ì—°ì† ëª¨ë‹ˆí„°ë§

```bash
# 1ì‹œê°„ ë™ì•ˆ ë§¤ 10ë¶„ë§ˆë‹¤ í”„ë¡œíŒŒì¼ë§
while true; do
    python scripts/profile.py
    sleep 600  # 10ë¶„
done
```

---

## ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 1. ì •ê¸° í”„ë¡œíŒŒì¼ë§

- **ì£¼ 1íšŒ**: ì „ì²´ í”„ë¡œíŒŒì¼ë§
- **ë°°í¬ ì „**: ì„±ëŠ¥ íšŒê·€ í™•ì¸
- **ìµœì í™” í›„**: íš¨ê³¼ ì¸¡ì •

### 2. ëª©í‘œ ì„¤ì •

ê° ì»´í¬ë„ŒíŠ¸ì˜ ëª©í‘œ ë ˆì´í„´ì‹œë¥¼ ëª…í™•íˆ í•˜ê³ , ì´ˆê³¼ ì‹œ ì•Œë¦¼

### 3. ë³‘ëª© ìš°ì„ ìˆœìœ„

1. **Critical**: P95 > ëª©í‘œì˜ 2ë°°
2. **High**: P95 > ëª©í‘œì˜ 1.5ë°°
3. **Medium**: P95 > ëª©í‘œì˜ 1.2ë°°

### 4. A/B í…ŒìŠ¤íŠ¸

ìµœì í™” ì „í›„ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ íš¨ê³¼ ê²€ì¦

```bash
# Before
python scripts/profile.py --output-dir before/

# ìµœì í™” ì ìš©

# After
python scripts/profile.py --output-dir after/

# ë¹„êµ
python scripts/compare_profiles.py before/ after/
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ: GPU ë©”íŠ¸ë¦­ì´ ìˆ˜ì§‘ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**:
```
âš  GPU ë©”íŠ¸ë¦­ì´ ì—†ì–´ GPU ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
```

**í•´ê²°**:
```bash
# nvidia-ml-py3 ì„¤ì¹˜
pip install nvidia-ml-py3

# NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# PyTorch CUDA í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"
```

### ë¬¸ì œ: ì°¨íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**:
```
âš  matplotlibê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.
```

**í•´ê²°**:
```bash
pip install matplotlib
```

### ë¬¸ì œ: í”„ë¡œíŒŒì¼ë§ì´ ë„ˆë¬´ ëŠë¦¼

**í•´ê²°**:
```bash
# ìƒ˜í”Œ ìˆ˜ ì¤„ì´ê¸°
python scripts/profile.py --samples 10

# íŠ¹ì • ì»´í¬ë„ŒíŠ¸ë§Œ
python scripts/profile.py --components stt
```

---

## ì°¸ê³  ìë£Œ

- [Performance Optimization Guide](./OPTIMIZATION_GUIDE.md)
- [Memory Profiling](https://docs.python.org/3/library/profile.html)
- [NVIDIA Profiler](https://developer.nvidia.com/nsight-systems)

---

## ë¬¸ì˜

ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì˜ëŠ” ì´ìŠˆ íŠ¸ë˜ì»¤ì— ë“±ë¡í•´ì£¼ì„¸ìš”.
