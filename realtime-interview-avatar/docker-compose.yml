# ============================================================================
# Docker Compose for Realtime Interview Avatar System
# MuseTalk V1.5 + ElevenLabs TTS + TensorRT/ONNX 최적화
# ============================================================================
#
# 사용법:
#   1. start_docker.bat 더블클릭 (빌드 + 실행)
#   또는:
#   1. docker-compose build
#   2. docker-compose up -d
#   3. http://localhost:5000 접속
#
# ============================================================================

version: '3.8'

services:
  avatar-server:
    build:
      context: ..
      dockerfile: realtime-interview-avatar/Dockerfile
    image: realtime-avatar:latest
    container_name: avatar-server
    restart: unless-stopped

    # GPU 지원 (RTX 50 시리즈 - CUDA 12.4, PyTorch nightly cu129)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    ports:
      - "5000:5000"

    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      # API Keys (from .env)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - LLM_API_URL=${LLM_API_URL:-}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_MODEL=${LLM_MODEL:-}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY:-}
      # Model paths
      - MUSETALK_PATH=/app/MuseTalk
      # TensorRT/ONNX optimization
      - ENABLE_TENSORRT=${ENABLE_TENSORRT:-true}
      - PRECISION_MODE=${PRECISION_MODE:-fp16}
      # PyTorch CUDA library paths
      - LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/nvidia/nvjitlink/lib:/usr/local/lib/python3.10/dist-packages/nvidia/cuda_runtime/lib:/usr/local/lib/python3.10/dist-packages/nvidia/cublas/lib:/usr/local/lib/python3.10/dist-packages/nvidia/cudnn/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64

    volumes:
      # MuseTalk 모델 (필수) - TensorRT 캐시 저장을 위해 쓰기 허용
      - ./models:/app/realtime-interview-avatar/models
      - ../MuseTalk/models:/app/MuseTalk/models:ro

      # 사전계산 아바타 (필수)
      - ./precomputed:/app/realtime-interview-avatar/precomputed:ro

      # 결과 및 에셋 (쓰기 가능)
      - ./results:/app/realtime-interview-avatar/results
      - ./assets:/app/realtime-interview-avatar/assets

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/v2/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s

    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

networks:
  default:
    driver: bridge
